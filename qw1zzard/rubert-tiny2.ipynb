{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchmetrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "MODEL_NAME = 'cointegrated/rubert-tiny2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: list[str],\n",
    "        labels: list[str],\n",
    "        tokenizer: AutoTokenizer,\n",
    "        max_length: int = 512,\n",
    "    ) -> None:\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        steps_per_epoch=None,\n",
    "        max_epochs=None,\n",
    "        lr=2e-5,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(MODEL_NAME).train()\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.pre_classifier = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, num_classes, bias=True),\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.max_epochs = max_epochs\n",
    "        self.lr = lr\n",
    "\n",
    "        self.train_accuracy = torchmetrics.Accuracy(\n",
    "            task='multiclass',\n",
    "            num_classes=num_classes,\n",
    "            average='macro',\n",
    "        )\n",
    "        self.val_accuracy = torchmetrics.Accuracy(\n",
    "            task='multiclass',\n",
    "            num_classes=num_classes,\n",
    "            average='macro',\n",
    "        )\n",
    "\n",
    "        self.train_precision = torchmetrics.Precision(\n",
    "            task='multiclass',\n",
    "            num_classes=num_classes,\n",
    "            average='macro',\n",
    "        )\n",
    "        self.train_recall = torchmetrics.Recall(\n",
    "            task='multiclass',\n",
    "            num_classes=num_classes,\n",
    "            average='macro',\n",
    "        )\n",
    "        self.train_f1 = torchmetrics.F1Score(\n",
    "            task='multiclass',\n",
    "            num_classes=num_classes,\n",
    "            average='macro',\n",
    "        )\n",
    "\n",
    "        self.val_precision = torchmetrics.Precision(\n",
    "            task='multiclass',\n",
    "            num_classes=num_classes,\n",
    "            average='macro',\n",
    "        )\n",
    "        self.val_recall = torchmetrics.Recall(\n",
    "            task='multiclass',\n",
    "            num_classes=num_classes,\n",
    "            average='macro',\n",
    "        )\n",
    "        self.val_f1 = torchmetrics.F1Score(\n",
    "            task='multiclass',\n",
    "            num_classes=num_classes,\n",
    "            average='macro',\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)[1]\n",
    "        return self.classifier(outputs)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        outputs = self(batch['input_ids'], batch['attention_mask'])\n",
    "        labels = batch['labels']\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "        preds = outputs.softmax(dim=-1)\n",
    "        self.train_accuracy.update(preds, labels)\n",
    "        self.train_precision.update(preds, labels)\n",
    "        self.train_recall.update(preds, labels)\n",
    "        self.train_f1.update(preds, labels)\n",
    "\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        accuracy = self.train_accuracy.compute()\n",
    "        precision = self.train_precision.compute()\n",
    "        recall = self.train_recall.compute()\n",
    "        f1 = self.train_f1.compute()\n",
    "\n",
    "        self.log('train_accuracy', accuracy, on_epoch=True)\n",
    "        self.log('train_precision', precision, on_epoch=True)\n",
    "        self.log('train_recall', recall, on_epoch=True)\n",
    "        self.log('train_f1', f1, on_epoch=True)\n",
    "\n",
    "        print(\n",
    "            f'Epoch: {self.current_epoch}, Train Accuracy: {accuracy:.4f}, '\n",
    "            f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}'\n",
    "        )\n",
    "\n",
    "        self.train_accuracy.reset()\n",
    "        self.train_precision.reset()\n",
    "        self.train_recall.reset()\n",
    "        self.train_f1.reset()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(batch['input_ids'], batch['attention_mask'])\n",
    "        labels = batch['labels']\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "        preds = outputs.softmax(dim=-1)\n",
    "        self.val_accuracy.update(preds, labels)\n",
    "        self.val_precision.update(preds, labels)\n",
    "        self.val_recall.update(preds, labels)\n",
    "        self.val_f1.update(preds, labels)\n",
    "\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        accuracy = self.val_accuracy.compute()\n",
    "        precision = self.val_precision.compute()\n",
    "        recall = self.val_recall.compute()\n",
    "        f1 = self.val_f1.compute()\n",
    "\n",
    "        self.log('val_accuracy', accuracy, on_epoch=True)\n",
    "        self.log('val_precision', precision, on_epoch=True)\n",
    "        self.log('val_recall', recall, on_epoch=True)\n",
    "        self.log('val_f1', f1, on_epoch=True)\n",
    "\n",
    "        print(\n",
    "            f'Epoch: {self.current_epoch}, Validation Accuracy: {accuracy:.4f}, '\n",
    "            f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}'\n",
    "        )\n",
    "\n",
    "        self.val_accuracy.reset()\n",
    "        self.val_precision.reset()\n",
    "        self.val_recall.reset()\n",
    "        self.val_f1.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_or_remove_punctuation(text: str) -> str:\n",
    "    punctuations = [',', '.', '!', '?']\n",
    "    words = text.split()\n",
    "\n",
    "    if random.random() < 0.5:\n",
    "        position = random.randint(0, len(words) - 1)\n",
    "        punct = random.choice(punctuations)\n",
    "        words[position] = words[position] + punct\n",
    "    else:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        words = text.split()\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def introduce_typo(text: str) -> str:\n",
    "    words = text.split()\n",
    "    index = random.randint(0, len(words) - 1)\n",
    "    word = words[index]\n",
    "\n",
    "    typo_type = random.choice(['swap', 'remove', 'duplicate'])\n",
    "\n",
    "    if typo_type == 'swap' and len(word) > 1:\n",
    "        pos = random.randint(0, len(word) - 2)\n",
    "        word = list(word)\n",
    "        word[pos], word[pos + 1] = word[pos + 1], word[pos]\n",
    "        words[index] = ''.join(word)\n",
    "\n",
    "    elif typo_type == 'remove' and len(word) > 1:\n",
    "        pos = random.randint(0, len(word) - 1)\n",
    "        words[index] = word[:pos] + word[pos + 1 :]\n",
    "\n",
    "    elif typo_type == 'duplicate':\n",
    "        pos = random.randint(0, len(word) - 1)\n",
    "        words[index] = word[:pos] + word[pos] + word[pos:]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def shuffle_words(text: str) -> str:\n",
    "    words = text.split()\n",
    "    if len(words) > 1:\n",
    "        random.shuffle(words)\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "AUG_NUM = 30\n",
    "\n",
    "\n",
    "def balance_dataset(texts: list[str], labels: list[int]):\n",
    "    df = pd.DataFrame({'question': texts, 'content': labels})\n",
    "\n",
    "    max_count = df['content'].value_counts().max()\n",
    "    augmented_data = []\n",
    "\n",
    "    for _, group in tqdm(df.groupby('content')):\n",
    "        count = len(group)\n",
    "        augmented_data.extend(group.to_dict('records'))\n",
    "\n",
    "        for _ in range(min(AUG_NUM, max_count - count)):\n",
    "            row = group.sample(1).iloc[0].to_dict()\n",
    "            question = row['question']\n",
    "\n",
    "            augmented_question = add_or_remove_punctuation(question)\n",
    "            augmented_question = introduce_typo(augmented_question)\n",
    "            augmented_question = shuffle_words(augmented_question)\n",
    "\n",
    "            new_row = row.copy()\n",
    "            new_row['question'] = augmented_question\n",
    "            augmented_data.append(new_row)\n",
    "\n",
    "    augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "    balanced_texts = augmented_df['question'].tolist()\n",
    "    balanced_labels = augmented_df['content'].tolist()\n",
    "\n",
    "    return balanced_texts, balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "    texts: list[str],\n",
    "    labels: list[str],\n",
    "    max_length: int,\n",
    "    batch_size: int,\n",
    "):\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        texts,\n",
    "        labels,\n",
    "        test_size=0.15,\n",
    "        random_state=42,\n",
    "        stratify=labels,\n",
    "    )\n",
    "\n",
    "    train_texts, train_labels = balance_dataset(train_texts, train_labels)\n",
    "    print(f'Train size: {len(train_labels)}, Valid size: {len(val_labels)}')\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    train_dataset = TextDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "    val_dataset = TextDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    texts,\n",
    "    labels,\n",
    "    num_classes,\n",
    "    max_length=512,\n",
    "    batch_size=16,\n",
    "    max_epochs=5,\n",
    "    lr=2e-5,\n",
    "):\n",
    "    train_loader, val_loader, label_encoder = preprocess_data(\n",
    "        texts, labels, max_length, batch_size\n",
    "    )\n",
    "\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    model = BERTClassifier(\n",
    "        num_classes=num_classes,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        max_epochs=max_epochs,\n",
    "        lr=lr,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1 if torch.cuda.is_available() else None,\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    return model, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('LK_modified.xlsx - Вопрос ответ.csv')\n",
    "df = df[df['content'].duplicated(keep=False)]\n",
    "\n",
    "texts = df['question'].to_list()\n",
    "labels = df['content'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83a13ac4175403fa89608493480db7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4805, Valid size: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\research\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\GitHub\\research\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | bert            | BertModel           | 29.2 M | train\n",
      "1  | pre_classifier  | Linear              | 97.7 K | train\n",
      "2  | classifier      | Sequential          | 36.6 K | train\n",
      "3  | loss_fn         | CrossEntropyLoss    | 0      | train\n",
      "4  | train_accuracy  | MulticlassAccuracy  | 0      | train\n",
      "5  | val_accuracy    | MulticlassAccuracy  | 0      | train\n",
      "6  | train_precision | MulticlassPrecision | 0      | train\n",
      "7  | train_recall    | MulticlassRecall    | 0      | train\n",
      "8  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "9  | val_precision   | MulticlassPrecision | 0      | train\n",
      "10 | val_recall      | MulticlassRecall    | 0      | train\n",
      "11 | val_f1          | MulticlassF1Score   | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "29.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.3 M    Total params\n",
      "117.312   Total estimated model params size (MB)\n",
      "80        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9177d95fb3e94a459d6172d51fb122e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\research\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "d:\\GitHub\\research\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Validation Accuracy: 0.0000, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\research\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842983c34f4844b5b0775ace3926dad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67254bebee645f3835c12099ba18a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Validation Accuracy: 0.0269, Precision: 0.0179, Recall: 0.0269, F1: 0.0199\n",
      "Epoch: 0, Train Accuracy: 0.0257, Precision: 0.0588, Recall: 0.0257, F1: 0.0194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c472e393de495e87aecc9e842ebaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Validation Accuracy: 0.1862, Precision: 0.1635, Recall: 0.1862, F1: 0.1678\n",
      "Epoch: 1, Train Accuracy: 0.1405, Precision: 0.2885, Recall: 0.1405, F1: 0.1478\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a8aab57a634f958add18fcc8e7291c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Validation Accuracy: 0.2161, Precision: 0.2176, Recall: 0.2161, F1: 0.2094\n",
      "Epoch: 2, Train Accuracy: 0.2510, Precision: 0.5089, Recall: 0.2510, F1: 0.2707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be70ecee9cd465c89fc4a73b47f7c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Validation Accuracy: 0.3233, Precision: 0.3274, Recall: 0.3233, F1: 0.3180\n",
      "Epoch: 3, Train Accuracy: 0.3526, Precision: 0.6039, Recall: 0.3526, F1: 0.3817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a703c0550ed46f7beb124db9b66d80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Validation Accuracy: 0.3411, Precision: 0.3463, Recall: 0.3411, F1: 0.3381\n",
      "Epoch: 4, Train Accuracy: 0.4651, Precision: 0.7344, Recall: 0.4651, F1: 0.4997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b114583d7d486a8fc505358dd0210f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Validation Accuracy: 0.5081, Precision: 0.5117, Recall: 0.5081, F1: 0.5044\n",
      "Epoch: 5, Train Accuracy: 0.5513, Precision: 0.8211, Recall: 0.5513, F1: 0.5840\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d357cc190a1948069a8b8573de7fbb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Validation Accuracy: 0.5249, Precision: 0.5515, Recall: 0.5249, F1: 0.5252\n",
      "Epoch: 6, Train Accuracy: 0.6463, Precision: 0.8625, Recall: 0.6463, F1: 0.6800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b78cb03e1db45149d9119542d3b7c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Validation Accuracy: 0.5249, Precision: 0.5439, Recall: 0.5249, F1: 0.5240\n",
      "Epoch: 7, Train Accuracy: 0.7386, Precision: 0.8841, Recall: 0.7386, F1: 0.7670\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5102566de9224121872a806731ccafbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Validation Accuracy: 0.5613, Precision: 0.5728, Recall: 0.5613, F1: 0.5597\n",
      "Epoch: 8, Train Accuracy: 0.7956, Precision: 0.9147, Recall: 0.7956, F1: 0.8167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1ecfe02d3b48058d72ac768156265c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Validation Accuracy: 0.5848, Precision: 0.5813, Recall: 0.5848, F1: 0.5755\n",
      "Epoch: 9, Train Accuracy: 0.8541, Precision: 0.9382, Recall: 0.8541, F1: 0.8708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139bf0a7f4024e23b36cdaaeff165be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Validation Accuracy: 0.5841, Precision: 0.5807, Recall: 0.5841, F1: 0.5749\n",
      "Epoch: 10, Train Accuracy: 0.8874, Precision: 0.9432, Recall: 0.8874, F1: 0.8980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32b30e989fd4b3cb32cebd5c7e797ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Validation Accuracy: 0.5953, Precision: 0.6127, Recall: 0.5953, F1: 0.5921\n",
      "Epoch: 11, Train Accuracy: 0.9196, Precision: 0.9523, Recall: 0.9196, F1: 0.9264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5192de551334bccb5778ae983502689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Validation Accuracy: 0.5917, Precision: 0.6046, Recall: 0.5917, F1: 0.5839\n",
      "Epoch: 12, Train Accuracy: 0.9400, Precision: 0.9597, Recall: 0.9400, F1: 0.9447\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72288ca5ade46059b5b1859c4ef1efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Validation Accuracy: 0.6046, Precision: 0.6157, Recall: 0.6046, F1: 0.5961\n",
      "Epoch: 13, Train Accuracy: 0.9501, Precision: 0.9623, Recall: 0.9501, F1: 0.9529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8a16a133d6475ea8769dee3cfba28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Validation Accuracy: 0.6051, Precision: 0.6154, Recall: 0.6051, F1: 0.5972\n",
      "Epoch: 14, Train Accuracy: 0.9589, Precision: 0.9670, Recall: 0.9589, F1: 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(labels))\n",
    "model, label_encoder = train_model(texts, labels, num_classes, max_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Если в \"команде\" нет подчиненных сотрудников просьба обратиться в поддержку для корректировки\n"
     ]
    }
   ],
   "source": [
    "def predict_class(\n",
    "    model: BERTClassifier,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    text: str,\n",
    "    label_encoder: LabelEncoder,\n",
    "    device: str = 'cpu',\n",
    ") -> str:\n",
    "    inputs = tokenizer(\n",
    "        text, padding='max_length', truncation=True, max_length=64, return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "    predicted_class_id = predictions.item()\n",
    "    predicted_class_text = label_encoder.inverse_transform([predicted_class_id])[0]\n",
    "\n",
    "    return predicted_class_text\n",
    "\n",
    "\n",
    "model.eval()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "text = 'Не вижу свою команду в личном кабинете!'\n",
    "predicted_class_text = predict_class(model, tokenizer, text, label_encoder, device)\n",
    "print(f'Predicted class: {predicted_class_text}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
